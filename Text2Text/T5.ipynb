{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNszIuAkVyjxxPDjs5C553G"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Instalamos las dependencias necesarias"],"metadata":{"id":"ho8mao00d0Tj"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2iLiyLBGOAXN","executionInfo":{"status":"ok","timestamp":1700025000216,"user_tz":360,"elapsed":31178,"user":{"displayName":"Leonardo Ramírez Ramírez","userId":"09938537502845992624"}},"outputId":"7f45b27b-89e7-4fce-c9fa-5a51890cb5b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.35.1-py3-none-any.whl (7.9 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/7.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/7.9 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/7.9 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.19.1-py3-none-any.whl (311 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.1/311.1 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers<0.15,>=0.14 (from transformers)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n","Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.35.1\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Collecting accelerate\n","  Downloading accelerate-0.24.1-py3-none-any.whl (261 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.17.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.24.1\n"]}],"source":["!pip install transformers\n","!pip install sentencepiece\n","!pip install torch\n","# Para usar GPU precisiones\n","!pip install accelerate"]},{"cell_type":"markdown","source":["## Carga del modelo Flan T5 - Large"],"metadata":{"id":"lkpPyCKOd5Aw"}},{"cell_type":"code","source":["from transformers import T5Tokenizer, T5ForConditionalGeneration\n","import torch\n","\n","\n","tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-large\")\n","model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\", device_map=\"auto\", torch_dtype=torch.float16)\n","\n","input_text = 'Create a slogan: The slogan should contain exciting information about energy drinks'\n","input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n","n = 100\n","temp = 0.8\n","# Cantidad de tokens con mayor probabilidad que se considerarán para cada paso de generación\n","top = 50\n","sequences = 3\n","\n","outputs = model.generate(input_ids, max_length=n)\n","outputs = model.generate(input_ids, max_length=n, do_sample=True)\n","outputs = model.generate(input_ids, max_length=n, do_sample=True, temperature=temp)\n","outputs = model.generate(input_ids, max_length=n, temperature=temp, do_sample=True, num_return_sequences=sequences)\n","outputs = model.generate(input_ids, max_length=n, temperature=temp, do_sample=True, num_return_sequences=sequences, top_k=top)\n","\n","print(tokenizer.decode(outputs[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qf7YnZttOXFH","executionInfo":{"status":"ok","timestamp":1699987692404,"user_tz":360,"elapsed":35976,"user":{"displayName":"Leonardo Ramírez Ramírez","userId":"09938537502845992624"}},"outputId":"b3c378e0-dfbc-48dc-cfb0-9e7387db99b4"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"stream","name":"stdout","text":["<pad> If you want to live longer, be healthy and be happy</s><pad>\n"]}]},{"cell_type":"markdown","source":["## Carga de palabras al vocabulario\n","\n","Verificamos qué palabras utilizadas en el prompt no están dentro del vocabulario del modelo pre entrenado"],"metadata":{"id":"AD2vCNuBd-kA"}},{"cell_type":"code","source":["# Obtener el vocabulario del tokenizador\n","vocab = tokenizer.get_vocab()\n","\n","# Verificar si todas las palabras están en el vocabulario\n","missing_words = []\n","\n","words_to_check = input_text.split()\n","for word in words_to_check:\n","    if word not in vocab:\n","      missing_words.append(word)\n","      print(f\"{word} no está en el vocabulario.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M5VjDHAV0SUW","executionInfo":{"status":"ok","timestamp":1699855364653,"user_tz":360,"elapsed":593,"user":{"displayName":"Leonardo Ramírez Ramírez","userId":"09938537502845992624"}},"outputId":"a4651909-8a72-4f57-dffe-714742db4f5c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Create no está en el vocabulario.\n","slogan: no está en el vocabulario.\n","slogan no está en el vocabulario.\n","contain no está en el vocabulario.\n","exciting no está en el vocabulario.\n","drinks no está en el vocabulario.\n"]}]},{"cell_type":"markdown","source":["Agregamos las palabras desconocidas para que el modelo las tranforme en representaciones vectoriales para su procesamiento. **OJO** aún se requiere de ajuste fino para que el modelo sea capaz de generar los word embeddings correctamente."],"metadata":{"id":"kYmhHGjMeK84"}},{"cell_type":"code","source":["## Tokenizador personalizado\n","\n","# Nuevas palabras a agregar al vocabulario\n","\n","# Agregamos al vocabulario\n","tokenizer.add_tokens(missing_words)\n","model.resize_token_embeddings(len(tokenizer))\n","\n","\n","input_text = 'Create a slogan: The slogan should contain exciting information about energy drinks'\n","input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n","n = 100\n","temp = 0.8\n","# Cantidad de tokens con mayor probabilidad que se considerarán para cada paso de generación\n","top = 50\n","sequences = 3\n","\n","outputs = model.generate(input_ids, max_length=n)\n","outputs = model.generate(input_ids, max_length=n, do_sample=True)\n","outputs = model.generate(input_ids, max_length=n, do_sample=True, temperature=temp)\n","outputs = model.generate(input_ids, max_length=n, temperature=temp, do_sample=True, num_return_sequences=sequences)\n","outputs = model.generate(input_ids, max_length=n, temperature=temp, do_sample=True, num_return_sequences=sequences, top_k=top)\n","\n","print(tokenizer.decode(outputs[0]))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yKyBgsdKLlne","executionInfo":{"status":"ok","timestamp":1699855484409,"user_tz":360,"elapsed":3316,"user":{"displayName":"Leonardo Ramírez Ramírez","userId":"09938537502845992624"}},"outputId":"7080ed29-a385-4b5e-ff2a-0e2e39118c5d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<pad> give out</s><pad><pad><pad><pad><pad>\n"]}]},{"cell_type":"markdown","source":["## Ajuste fino del modelo\n","\n","A partir de un dataset personalizado, hacemos el ajuste fino del modelo con ejemplos específicos a la tarea que queremos que realice. El modelo contiene alrededor de 500 ejemplos."],"metadata":{"id":"RCUdbIkjeriC"}},{"cell_type":"code","source":["# Conectamos el entorno de Colab\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Ruta del archivo en Google Drive\n","dataset_path = '/content/drive/My Drive/Profesional/7mo Semestre - Profesional/Bloques 2 y 3/Reto - Generative IA/T5/Dataset_Coca_Cola_Flan_T5.json'\n","\n","import json\n","# Cargamos el conjunto de datos. Especificamos un codificador de bites UTF-8 para que Python lea el archivo JSON\n","with open(dataset_path, 'r', encoding='utf-8') as file:\n","    dataset_Coca = json.load(file)\n","\n","print(f'Estamos utilizando un dataset para el ajuste fino de T5 con {len(dataset_Coca)} ejemplos')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_7Kn3Ls24bqf","executionInfo":{"status":"ok","timestamp":1699987938241,"user_tz":360,"elapsed":661,"user":{"displayName":"Leonardo Ramírez Ramírez","userId":"09938537502845992624"}},"outputId":"304c5785-d2a2-4d6d-986f-9fb6c298e6ad"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Estamos utilizando un dataset para el ajuste fino de T5 con 453 ejemplos\n"]}]},{"cell_type":"code","source":["from transformers import T5ForConditionalGeneration, T5Tokenizer\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn.model_selection import train_test_split\n","import torch.optim as optim\n","import torch\n","from torch.nn.utils.rnn import pad_sequence\n","\n","# Divide el conjunto de datos en entrenamiento y validación\n","train_data, val_data = train_test_split(dataset_Coca, test_size=0.2, random_state=42)\n","\n","# Define tu conjunto de datos (asegúrate de tener un formato similar al que usaste para preentrenar)\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, examples, tokenizer):\n","        self.examples = examples\n","        self.tokenizer = tokenizer\n","\n","        # Calcula la longitud máxima dinámicamente\n","        self.max_sequence_length = max(len(self.tokenizer.encode(example['prompt'])) for example in examples)\n","\n","    def __len__(self):\n","        return len(self.examples)\n","\n","    def __getitem__(self, idx):\n","        example = self.examples[idx]\n","        prompt_tokens = self.tokenizer.encode(example['prompt'], truncation=True)\n","        target_tokens = self.tokenizer.encode(example['target'], truncation=True)\n","\n","        # Convertir a tensores de PyTorch\n","        inputs = torch.tensor(prompt_tokens, dtype=torch.long)\n","        labels = torch.tensor(target_tokens, dtype=torch.long)\n","\n","        return inputs, labels\n","\n","def collate_batch(batch):\n","    inputs, labels = zip(*batch)\n","\n","    # Usar pad_sequence para hacer el padding por separado en inputs y labels\n","    padded_inputs = pad_sequence(inputs, batch_first=True)\n","    padded_labels = pad_sequence(labels, batch_first=True)\n","\n","    return padded_inputs, padded_labels\n"],"metadata":{"id":"RlMIJNuue5k0","executionInfo":{"status":"ok","timestamp":1699992352169,"user_tz":360,"elapsed":200,"user":{"displayName":"Leonardo Ramírez Ramírez","userId":"09938537502845992624"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["inputs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GtHuNmGKehzq","executionInfo":{"status":"ok","timestamp":1699993751913,"user_tz":360,"elapsed":184,"user":{"displayName":"Leonardo Ramírez Ramírez","userId":"09938537502845992624"}},"outputId":"84cee474-257f-4d0a-9bf1-642417e52fcc"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 6357,    46,     3,    35,  1225,    53,  1154,    21,   638,  1050,\n","         12891,    10,     1,     0],\n","        [ 1642,     3,     9,  1643,    18,   715,  3898,    21, 25417,  3043,\n","             9, 18928,    10,     1]], device='cuda:0')"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["batch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FIIMCMvPfvOI","executionInfo":{"status":"ok","timestamp":1699995519169,"user_tz":360,"elapsed":288,"user":{"displayName":"Leonardo Ramírez Ramírez","userId":"09938537502845992624"}},"outputId":"15651389-e105-4d95-8228-e63f2630e9b9"},"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[  749,  2748,    15,     3,     9, 10468,  6754,  1154,    21,  6236,\n","          21131,    15, 18872,    10,     1],\n","         [ 4589,    95,    28,     3,     9,  1373,  1469,  1154,    21, 25417,\n","           3043,     9, 12891,    10,     1]]),\n"," tensor([[ 4783,     3,     9,  6236, 21131,    15, 10468,  5143,    11,   911,\n","              3,     9,  3898,    30,     3,     9,  2608,    18, 24186, 25417,\n","           3043,     9, 26565,    52,     5,     1],\n","         [ 4783,     3,     9, 25417,  3043,     9,  1373,  1469, 12927,    11,\n","            129,     3,     9,  3898,    30,    39,   416,  2914,  1190,     5,\n","              1,     0,     0,     0,     0,     0]]))"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["labels"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2TCay0LYg_mb","executionInfo":{"status":"ok","timestamp":1699993617261,"user_tz":360,"elapsed":106,"user":{"displayName":"Leonardo Ramírez Ramírez","userId":"09938537502845992624"}},"outputId":"766e3a7f-ea00-4d9a-8065-2b0252331ea7"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 4780,     3,     9,     3,    31,   134,   440,   935,   925,   102,\n","            31,  1154,     3,   104,   805,   136,   431, 25417,  3043,     9,\n","          6750,    11,   129,     3,     9,   339,  2608, 15580,     5,     1],\n","        [14839,   136,   314, 25417,  3043,     9,  6750,    11,   129, 10738,\n","           326,    39,   792,     5,     1,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n","       device='cuda:0')"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["# Configura el modelo y el tokenizador\n","tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-large\")\n","model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\", device_map=\"auto\", torch_dtype=torch.float16)\n","\n","\n","# Configura el optimizador\n","optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n","\n","# Configura tu conjunto de datos y DataLoader para entrenamiento\n","train_dataset = CustomDataset(train_data, tokenizer)\n","train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_batch)\n","\n","# Configura tu conjunto de datos y DataLoader para validación\n","val_dataset = CustomDataset(val_data, tokenizer)\n","val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, collate_fn=collate_batch)\n","\n","# Entrenamiento del modelo\n","num_epochs = 3\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_loss = 0\n","\n","    # Iteramos en los batch para mover los inputs y labels al hardware disponible\n","    for batch in train_loader:\n","        inputs, labels = batch\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","    #Proceso de entrenamiento: Se pasan los datos al modelo, se calcula el gradiente y se ajustan los pesos en la retropropagación\n","        optimizer.zero_grad()\n","        outputs = model(inputs, labels=labels)\n","        loss = outputs.loss\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    average_loss = total_loss / len(train_loader)\n","    print(f'Epoch {epoch + 1}, Average Training Loss: {average_loss}')\n","\n","    # Evaluación en el conjunto de validación\n","    model.eval()\n","    total_validation_loss = 0\n","\n","    with torch.no_grad():\n","        for batch in val_loader:\n","            inputs, labels = batch\n","            #inputs = {k: v.to(device) for k, v in inputs.items()}\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(inputs, labels=labels)\n","            loss = outputs.loss\n","\n","            total_validation_loss += loss.item()\n","\n","    average_validation_loss = total_validation_loss / len(val_loader)\n","    print(f'Epoch {epoch + 1}, Average Validation Loss: {average_validation_loss}')\n","\n","# Guarda el modelo ajustado\n","model.save_pretrained(\"fine_tuned_model\")\n","tokenizer.save_pretrained(\"fine_tuned_model\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"id":"Gbh2BBTfMj_-","executionInfo":{"status":"error","timestamp":1699994101740,"user_tz":360,"elapsed":87767,"user":{"displayName":"Leonardo Ramírez Ramírez","userId":"09938537502845992624"}},"outputId":"7be92e8f-83e1-4982-851b-aab598c7af16"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1, Average Training Loss: nan\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-39-d1ca090afbbf>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'items'"]}]},{"cell_type":"markdown","source":["Un resultado bueno que generó fue *Turn on the music, turn on the drinks*"],"metadata":{"id":"LnB0G5cw-rJ7"}},{"cell_type":"markdown","source":["Verificamos que las palabras del prompt estén incluidas en el **vocabulario** de T5"],"metadata":{"id":"ZdaORpT_KBlG"}},{"cell_type":"markdown","source":["-------------------------------------------------------------"],"metadata":{"id":"GKBkr_97PT_g"}}]}